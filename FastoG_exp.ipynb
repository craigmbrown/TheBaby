{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28eb054a-962b-499f-b348-6366590b1d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T11:34:54.236337Z",
     "iopub.status.busy": "2025-02-11T11:34:54.236012Z",
     "iopub.status.idle": "2025-02-11T11:34:56.103633Z",
     "shell.execute_reply": "2025-02-11T11:34:56.102608Z",
     "shell.execute_reply.started": "2025-02-11T11:34:54.236314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FastToG'...\n",
      "remote: Enumerating objects: 117, done.\u001b[K\n",
      "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
      "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
      "remote: Total 117 (delta 60), reused 46 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (117/117), 21.91 MiB | 33.84 MiB/s, done.\n",
      "Resolving deltas: 100% (60/60), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dosonleung/FastToG.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92fd64c-17b7-4ac4-914f-1d0c3100ddcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:58:26.289717Z",
     "iopub.status.busy": "2025-02-11T17:58:26.289383Z",
     "iopub.status.idle": "2025-02-11T17:58:32.277254Z",
     "shell.execute_reply": "2025-02-11T17:58:32.276342Z",
     "shell.execute_reply.started": "2025-02-11T17:58:26.289691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
      "Collecting python-louvain\n",
      "  Downloading python-louvain-0.16.tar.gz (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.11.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Building wheels for collected packages: python-louvain\n",
      "  Building wheel for python-louvain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-louvain: filename=python_louvain-0.16-py3-none-any.whl size=9390 sha256=6a3de464672706fda981ed78b69bc5dfc3bc7007c78ff3f32a50c55691e2928e\n",
      "  Stored in directory: /root/.cache/pip/wheels/11/c1/e7/f62a211c636275e2da798bf0c307a3ae79aeddaf2524a03ce4\n",
      "Successfully built python-louvain\n",
      "Installing collected packages: python-louvain\n",
      "Successfully installed python-louvain-0.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install networkx python-louvain scikit-learn scipy numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b3a7b-bbc1-4186-a847-46fe31f134b5",
   "metadata": {},
   "source": [
    "# Define a test set of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4934f0d7-4750-447e-a664-fd94361ec3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T17:58:32.279634Z",
     "iopub.status.busy": "2025-02-11T17:58:32.279336Z",
     "iopub.status.idle": "2025-02-11T17:58:32.290137Z",
     "shell.execute_reply": "2025-02-11T17:58:32.289142Z",
     "shell.execute_reply.started": "2025-02-11T17:58:32.279605Z"
    }
   },
   "outputs": [],
   "source": [
    "query_entity_mappings = {\n",
    "    # Simple single-hop queries\n",
    "    \"What tools does Ada use?\": {\n",
    "        \"start_entity\": \"Agent (Ada)\",\n",
    "        \"related_labels\": [\"Tool\"]\n",
    "    },\n",
    "    \n",
    "    \"Which resources does Ada configure?\": {\n",
    "        \"start_entity\": \"Agent (Ada)\",\n",
    "        \"related_labels\": [\"Resource\"]\n",
    "    },\n",
    "    \n",
    "    \"What is the name of Mickey Drexler's father?\": {\n",
    "        \"start_entity\": \"Agent (Mickey Drexler)\",\n",
    "        \"related_labels\": [\"Agent (Mickey Drexler's Father)\"]\n",
    "    },\n",
    "    \n",
    "    \"List all AI Assistants in the system.\": {\n",
    "        \"start_entity\": None,  # General query\n",
    "        \"related_labels\": [\"Ai_assistant\"]\n",
    "    },\n",
    "    \n",
    "    # Multi-hop relationship queries\n",
    "    \"Which retail companies has Mickey Drexler been involved with?\": {\n",
    "        \"start_entity\": \"Agent (Mickey Drexler)\",\n",
    "        \"related_labels\": [\"Resource\"]  # Companies like The Gap, Ann Taylor, etc.\n",
    "    },\n",
    "    \n",
    "    \"What is the connection between Steve Jobs and Mickey Drexler?\": {\n",
    "        \"start_entity\": \"Agent (Steve Jobs)\",\n",
    "        \"related_labels\": [\"Agent (Mickey Drexler)\", \"Resource (Apple Store)\"]\n",
    "    },\n",
    "    \n",
    "    \"How is the Apple Store connected to both Steve Jobs and Mickey Drexler?\": {\n",
    "        \"start_entity\": \"Resource (Apple Store)\",\n",
    "        \"related_labels\": [\"Agent (Steve Jobs)\", \"Agent (Mickey Drexler)\"]\n",
    "    },\n",
    "    \n",
    "    \"What tools and resources are used by both Ada and Indy Dev Dan?\": {\n",
    "        \"start_entity\": \"Agent (Ada)\",\n",
    "        \"related_labels\": [\"Agent (Indy Dev Dan)\", \"Tool\", \"Resource\"]\n",
    "    },\n",
    "    \n",
    "    # Community-based queries\n",
    "    \"What are all the relationships between AI Agents and the tools they use?\": {\n",
    "        \"start_entity\": \"Ai_agent\",\n",
    "        \"related_labels\": [\"Tool\"]\n",
    "    },\n",
    "    \n",
    "    \"How do different AI assistants utilize structured outputs and reasoning models?\": {\n",
    "        \"start_entity\": \"Ai_assistant\",\n",
    "        \"related_labels\": [\"Structuredoutput\", \"Reasoningmodel\"]\n",
    "    },\n",
    "    \n",
    "    \"What is the complete ecosystem around Generative AI, including its agents and assistants?\": {\n",
    "        \"start_entity\": \"Generativeai\",\n",
    "        \"related_labels\": [\"Ai_agent\", \"Ai_assistant\"]\n",
    "    },\n",
    "    \n",
    "    \"Map out the full retail network connected to Mickey Drexler, including all companies and relationships.\": {\n",
    "        \"start_entity\": \"Agent (Mickey Drexler)\",\n",
    "        \"related_labels\": [\"Resource\"]  # Various retail companies\n",
    "    },\n",
    "    \n",
    "    # Complex reasoning queries\n",
    "    \"What are the common patterns in how AI Agents and AI Assistants interact with prompts and models?\": {\n",
    "        \"start_entity\": \"Ai_agent\",\n",
    "        \"related_labels\": [\"Ai_assistant\", \"Prompt\", \"Model\"]\n",
    "    },\n",
    "    \n",
    "    \"Compare the technology stack used by Ada versus other AI assistants in the system.\": {\n",
    "        \"start_entity\": \"Agent (Ada)\",\n",
    "        \"related_labels\": [\"Ai_assistant\", \"Tool\", \"Resource\"]\n",
    "    },\n",
    "    \n",
    "    \"What is the relationship between the Orchestration Layer and AI Agents, including all downstream connections?\": {\n",
    "        \"start_entity\": \"Orchestrationlayer\",\n",
    "        \"related_labels\": [\"Ai_agent\"]\n",
    "    },\n",
    "    \n",
    "    \"Trace the complete path of how Generative AI connects to Engineers through various components.\": {\n",
    "        \"start_entity\": \"Generativeai\",\n",
    "        \"related_labels\": [\"Engineer\"]\n",
    "    },\n",
    "    \n",
    "    # Aggregation queries\n",
    "    \"How many different types of tools are used across all agents?\": {\n",
    "        \"start_entity\": \"Agent\",\n",
    "        \"related_labels\": [\"Tool\"]\n",
    "    },\n",
    "    \n",
    "    \"What is the most commonly used resource type in the system?\": {\n",
    "        \"start_entity\": None,  # System-wide query\n",
    "        \"related_labels\": [\"Resource\"]\n",
    "    },\n",
    "    \n",
    "    \"Which agent has the most diverse set of connections?\": {\n",
    "        \"start_entity\": \"Agent\",\n",
    "        \"related_labels\": [\"Tool\", \"Resource\"]\n",
    "    },\n",
    "    \n",
    "    \"What are all the different ways prompts are used throughout the system?\": {\n",
    "        \"start_entity\": \"Prompt\",\n",
    "        \"related_labels\": [\"Ai_agent\", \"Largelanguagemodel\"]\n",
    "    },\n",
    "    \n",
    "    # Cross-domain queries\n",
    "    \"How do retail business practices (from Mickey Drexler) connect with technology (through Apple Store)?\": {\n",
    "        \"start_entity\": \"Agent (Mickey Drexler)\",\n",
    "        \"related_labels\": [\"Resource (Apple Store)\", \"Tool\"]\n",
    "    },\n",
    "    \n",
    "    \"What patterns emerge when comparing human agents versus AI agents in terms of resource usage?\": {\n",
    "        \"start_entity\": \"Agent\",\n",
    "        \"related_labels\": [\"Ai_agent\", \"Resource\"]\n",
    "    },\n",
    "    \n",
    "    \"Map the complete knowledge flow from Engineers through to AI Assistants and their outputs.\": {\n",
    "        \"start_entity\": \"Engineer\",\n",
    "        \"related_labels\": [\"Ai_assistant\", \"Structuredoutput\"]\n",
    "    },\n",
    "    \n",
    "    \"How do different types of agents (human, AI, assistants) compare in their use of tools and resources?\": {\n",
    "        \"start_entity\": \"Agent\",\n",
    "        \"related_labels\": [\"Ai_agent\", \"Ai_assistant\", \"Tool\", \"Resource\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f09323-004a-4004-950d-9e9ad934417a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:02:33.777115Z",
     "iopub.status.busy": "2025-02-11T18:02:33.776251Z",
     "iopub.status.idle": "2025-02-11T18:02:50.520864Z",
     "shell.execute_reply": "2025-02-11T18:02:50.519897Z",
     "shell.execute_reply.started": "2025-02-11T18:02:33.777084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain_neo4j\n",
      "  Downloading langchain_neo4j-0.3.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langchain_core\n",
      "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.8.0)\n",
      "Collecting langchain<0.4.0,>=0.3.7 (from langchain_neo4j)\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: neo4j<6.0.0,>=5.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain_neo4j) (5.28.1)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_core)\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain_core)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain_core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain_core) (5.4.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain_core)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<0.4.0,>=0.3.7->langchain_neo4j)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_neo4j) (2.0.21)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_neo4j) (2.31.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_neo4j) (3.9.1)\n",
      "Collecting numpy<2,>=1.26.4 (from langchain<0.4.0,>=0.3.7->langchain_neo4j)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain_core)\n",
      "  Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_core)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pytz in /usr/lib/python3/dist-packages (from neo4j<6.0.0,>=5.25.0->langchain_neo4j) (2022.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.66.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain_core)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.5.2->langchain_core)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.7->langchain_neo4j) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.7->langchain_neo4j) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.7->langchain_neo4j) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.7->langchain_neo4j) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.7->langchain_neo4j) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain_neo4j) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain_neo4j) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.7->langchain_neo4j) (1.1.2)\n",
      "Downloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_neo4j-0.3.0-py3-none-any.whl (38 kB)\n",
      "Downloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, tenacity, pydantic-core, orjson, numpy, jsonpatch, annotated-types, pydantic, langsmith, langchain_core, langchain-text-splitters, langchain_openai, langchain, langchain_neo4j\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.14\n",
      "    Uninstalling pydantic-1.10.14:\n",
      "      Successfully uninstalled pydantic-1.10.14\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.10.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.7.0 jsonpatch-1.33 langchain-0.3.18 langchain-text-splitters-0.3.6 langchain_core-0.3.34 langchain_neo4j-0.3.0 langchain_openai-0.3.4 langsmith-0.3.8 numpy-1.26.4 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 tenacity-9.0.0 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -qU install python-dotenv langchain_openai langchain_neo4j langchain_core igraph python-louvain  networkx cdlib scikit-learn neo4j httpx tiktoken openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7259f3-431d-481f-9768-85f97e8c59d1",
   "metadata": {},
   "source": [
    "# FILL IN YOUR API KEYS AND ENV VARIABLES BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05938e6-0a30-48eb-817e-3c8ebab95a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:01:47.409981Z",
     "iopub.status.busy": "2025-02-11T18:01:47.409283Z",
     "iopub.status.idle": "2025-02-11T18:01:47.415197Z",
     "shell.execute_reply": "2025-02-11T18:01:47.414046Z",
     "shell.execute_reply.started": "2025-02-11T18:01:47.409953Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"NEO4J_URI\"]=\"\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"\"\n",
    "os.environ[\"NEO4J_USER\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d28d12-2552-4be0-846e-b5d0b85460b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:59:40.999334Z",
     "iopub.status.busy": "2025-02-11T15:59:40.998944Z",
     "iopub.status.idle": "2025-02-11T15:59:41.004509Z",
     "shell.execute_reply": "2025-02-11T15:59:41.003379Z",
     "shell.execute_reply.started": "2025-02-11T15:59:40.999300Z"
    }
   },
   "source": [
    "# FastoG vs GraphRAG Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15afab-c2da-48ef-9d31-5d4d4f49c416",
   "metadata": {},
   "source": [
    "## Run GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580e6935-fdfc-40a6-90c8-50777ba279d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:09:35.872785Z",
     "iopub.status.busy": "2025-02-11T18:09:35.871651Z",
     "iopub.status.idle": "2025-02-11T18:09:44.524284Z",
     "shell.execute_reply": "2025-02-11T18:09:44.523349Z",
     "shell.execute_reply.started": "2025-02-11T18:09:35.872747Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_neo4j import Neo4jGraph, Neo4jVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List, TypedDict\n",
    "from typing_extensions import Annotated, Union\n",
    "from langchain.schema import Document\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM and graph connection (with enhanced schema for better details)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "graph = Neo4jGraph(\n",
    "    enhanced_schema=True,\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USER\"),\n",
    "    password=\"os.getenv(\"NEO4J_PASSWORD\")\n",
    ")\n",
    "graph.refresh_schema()\n",
    "\n",
    "# Define the overall state with similarity_results included.\n",
    "class OverallState(TypedDict):\n",
    "    question: str\n",
    "    next_action: str\n",
    "    cypher_statement: str\n",
    "    cypher_errors: List[str]\n",
    "    database_records: List[dict]\n",
    "    similarity_results: Union[List[dict],List[Document]]\n",
    "    steps: Annotated[List[str], list]\n",
    "\n",
    "# STEP 1: Generate a Cypher query from the user question.\n",
    "def generate_cypher(state: OverallState) -> OverallState:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Convert the following question to a Cypher query. Return only the query.\"),\n",
    "        (\"human\", \"Question: {question}\\nCypher:\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    state[\"cypher_statement\"] = chain.invoke({\"question\": state[\"question\"]})\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"generate_cypher\"]\n",
    "    return state\n",
    "\n",
    "# STEP 2: Validate the generated Cypher query.\n",
    "def validate_cypher(state: OverallState) -> OverallState:\n",
    "    errors = []\n",
    "    try:\n",
    "        # Using EXPLAIN to check syntax (adjust as needed)\n",
    "        graph.query(f\"EXPLAIN {state['cypher_statement']}\")\n",
    "    except Exception as e:\n",
    "        errors.append(str(e))\n",
    "    state[\"cypher_errors\"] = errors\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"validate_cypher\"]\n",
    "    # If errors exist, mark for correction\n",
    "    state[\"next_action\"] = \"correct_cypher\" if errors else \"execute_cypher\"\n",
    "    return state\n",
    "\n",
    "# STEP 3: Correct the Cypher query if errors were found.\n",
    "def correct_cypher(state: OverallState) -> OverallState:\n",
    "    if state[\"next_action\"] != \"correct_cypher\":\n",
    "        return state\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a Cypher expert. Correct the errors in the following Cypher query.\"),\n",
    "        (\"human\", \"Errors: {cypher_errors}\\nOriginal Cypher: {cypher_statement}\\nCorrected Cypher: IMPORTANT: return just the cypher query diectly and only\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    corrected = chain.invoke({\n",
    "        \"cypher_errors\": state[\"cypher_errors\"],\n",
    "        \"cypher_statement\": state[\"cypher_statement\"]\n",
    "    })\n",
    "    state[\"cypher_statement\"] = corrected\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"correct_cypher\"]\n",
    "    state[\"next_action\"] = \"execute_cypher\"\n",
    "    return state\n",
    "\n",
    "# STEP 4: Execute the Cypher query against Neo4j.\n",
    "def execute_cypher(state: OverallState) -> OverallState:\n",
    "    records = graph.query(state[\"cypher_statement\"])\n",
    "    state[\"database_records\"] = records if records else []\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"execute_cypher\"]\n",
    "    return state\n",
    "\n",
    "# STEP 5: Run similarity search using an existing Neo4j vector index.\n",
    "def execute_similarity_search(state: OverallState) -> OverallState:\n",
    "    store = Neo4jVector.from_existing_index(\n",
    "        OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "        url=os.getenv(\"NEO4J_URI\"),\n",
    "        username=os.getenv(\"NEO4J_USER\"),\n",
    "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "        index_name=\"vector\" \n",
    "    )\n",
    "    # Run similarity search using the question (or you could use the cypher query if preferred)\n",
    "    state[\"similarity_results\"] = store.similarity_search_with_score(state[\"question\"],k=3)\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"similarity_search\"]\n",
    "    return state\n",
    "\n",
    "# STEP 6: Generate the final answer using both database and similarity search results.\n",
    "def generate_final_answer(state: OverallState) -> str:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"Given the following Neo4j query results:\\n{database_records}\\n\"\n",
    "                    \"And similarity search results:\\n{similarity_results}\\n\"\n",
    "                    \"Answer the question: {question}\")\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    state[\"steps\"] = state.get(\"steps\", []) + [\"generate_final_answer\"]\n",
    "    return chain.invoke({\n",
    "        \"database_records\": state.get(\"database_records\"),\n",
    "        \"similarity_results\": state.get(\"similarity_results\"),\n",
    "        \"question\": state[\"question\"]\n",
    "    })\n",
    "\n",
    "def main(user_query):\n",
    "\n",
    "    state: OverallState = {\n",
    "        \"question\": user_query,\n",
    "        \"next_action\": \"\",\n",
    "        \"cypher_statement\": \"\",\n",
    "        \"cypher_errors\": [],\n",
    "        \"database_records\": [],\n",
    "        \"similarity_results\": [],\n",
    "        \"steps\": []\n",
    "    }\n",
    "    state = generate_cypher(state)\n",
    "    state = validate_cypher(state)\n",
    "    if state[\"next_action\"] == \"correct_cypher\":\n",
    "        state = correct_cypher(state)\n",
    "    state = execute_cypher(state)\n",
    "    state = execute_similarity_search(state)\n",
    "    final_answer = generate_final_answer(state)\n",
    "    return final_answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b2f26-0489-487e-847f-8a63af9bb0ea",
   "metadata": {},
   "source": [
    "## GraphRAG Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c35d801-788b-4e37-a129-7b3ada4b25fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:37:44.070140Z",
     "iopub.status.busy": "2025-02-11T18:37:44.069467Z",
     "iopub.status.idle": "2025-02-11T18:44:18.901621Z",
     "shell.execute_reply": "2025-02-11T18:44:18.900715Z",
     "shell.execute_reply.started": "2025-02-11T18:37:44.070115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: CHILD_OF)} {position: line: 1, column: 45, offset: 44} for query: 'MATCH (p:Person {name: \"Mickey Drexler\"})-[:CHILD_OF]->(f:Person)\\nRETURN f.name'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AI_Assistant)} {position: line: 1, column: 10, offset: 9} for query: 'MATCH (a:AI_Assistant)\\nRETURN a'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: INVOLVED_WITH)} {position: line: 1, column: 45, offset: 44} for query: 'MATCH (m:Person {name: \"Mickey Drexler\"})-[:INVOLVED_WITH]->(c:Company)\\nWHERE c.industry = \"Retail\"\\nRETURN c.name'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Company)} {position: line: 1, column: 64, offset: 63} for query: 'MATCH (m:Person {name: \"Mickey Drexler\"})-[:INVOLVED_WITH]->(c:Company)\\nWHERE c.industry = \"Retail\"\\nRETURN c.name'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: industry)} {position: line: 2, column: 9, offset: 80} for query: 'MATCH (m:Person {name: \"Mickey Drexler\"})-[:INVOLVED_WITH]->(c:Company)\\nWHERE c.industry = \"Retail\"\\nRETURN c.name'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: KNOWS)} {position: line: 1, column: 42, offset: 41} for query: 'MATCH (p1:Person {name: \"Steve Jobs\"})-[:KNOWS*]-(p2:Person {name: \"Mickey Drexler\"})\\nRETURN p1, p2'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: CONNECTED_TO)} {position: line: 1, column: 41, offset: 40} for query: 'MATCH (a:Person {name: \"Steve Jobs\"})-[:CONNECTED_TO*]-(s:Store {name: \"Apple Store\"})-[:CONNECTED_TO*]-(m:Person {name: \"Mickey Drexler\"})\\nRETURN a, s, m'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: CONNECTED_TO)} {position: line: 1, column: 90, offset: 89} for query: 'MATCH (a:Person {name: \"Steve Jobs\"})-[:CONNECTED_TO*]-(s:Store {name: \"Apple Store\"})-[:CONNECTED_TO*]-(m:Person {name: \"Mickey Drexler\"})\\nRETURN a, s, m'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Store)} {position: line: 1, column: 59, offset: 58} for query: 'MATCH (a:Person {name: \"Steve Jobs\"})-[:CONNECTED_TO*]-(s:Store {name: \"Apple Store\"})-[:CONNECTED_TO*]-(m:Person {name: \"Mickey Drexler\"})\\nRETURN a, s, m'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: ToolOrResource)} {position: line: 1, column: 44, offset: 43} for query: \"MATCH (a:Person {name: 'Ada'})-[:USES]->(t:ToolOrResource)<-[:USES]-(b:Person {name: 'Indy Dev Dan'})\\nRETURN t\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AI_Agent)} {position: line: 1, column: 14, offset: 13} for query: 'MATCH (agent:AI_Agent)-[r]->(tool:Tool)\\nRETURN agent, r, tool'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AI_Assistant)} {position: line: 1, column: 11, offset: 10} for query: \"MATCH (ai:AI_Assistant)-[:UTILIZES]->(tech:Technology)\\nWHERE tech.name IN ['Structured Outputs', 'Reasoning Models']\\nRETURN ai.name AS AI_Assistant, collect(tech.name) AS Technologies_Utilized\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Ecosystem)} {position: line: 1, column: 10, offset: 9} for query: 'MATCH (e:Ecosystem {name: \"Generative AI\"})-[:INCLUDES]->(a:Agent), \\n      (e)-[:INCLUDES]->(as:Assistant)\\nRETURN e, collect(a) AS agents, collect(as) AS assistants'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Assistant)} {position: line: 2, column: 28, offset: 96} for query: 'MATCH (e:Ecosystem {name: \"Generative AI\"})-[:INCLUDES]->(a:Agent), \\n      (e)-[:INCLUDES]->(as:Assistant)\\nRETURN e, collect(a) AS agents, collect(as) AS assistants'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cypher generation exception\n",
      "cypher generation exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AI_Assistant)} {position: line: 1, column: 10, offset: 9} for query: \"MATCH (a:AI_Assistant {name: 'Ada'})-[:USES]->(t:Technology)\\nWITH collect(t) AS adaTech\\nMATCH (other:AI_Assistant)-[:USES]->(tech:Technology)\\nWHERE other.name <> 'Ada'\\nRETURN other.name AS Assistant, collect(tech) AS Technologies, adaTech\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AI_Assistant)} {position: line: 3, column: 14, offset: 101} for query: \"MATCH (a:AI_Assistant {name: 'Ada'})-[:USES]->(t:Technology)\\nWITH collect(t) AS adaTech\\nMATCH (other:AI_Assistant)-[:USES]->(tech:Technology)\\nWHERE other.name <> 'Ada'\\nRETURN other.name AS Assistant, collect(tech) AS Technologies, adaTech\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: OrchestrationLayer)} {position: line: 1, column: 10, offset: 9} for query: 'MATCH (o:OrchestrationLayer)-[r*]->(a:AIAgent)\\nRETURN o, r, a'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AIAgent)} {position: line: 1, column: 39, offset: 38} for query: 'MATCH (o:OrchestrationLayer)-[r*]->(a:AIAgent)\\nRETURN o, r, a'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: CONNECTS_TO)} {position: line: 1, column: 54, offset: 53} for query: \"MATCH path = (g:Component {name: 'Generative AI'})-[:CONNECTS_TO*]->(e:Component {name: 'Engineers'})\\nRETURN path\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Component)} {position: line: 1, column: 17, offset: 16} for query: \"MATCH path = (g:Component {name: 'Generative AI'})-[:CONNECTS_TO*]->(e:Component {name: 'Engineers'})\\nRETURN path\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Component)} {position: line: 1, column: 72, offset: 71} for query: \"MATCH path = (g:Component {name: 'Generative AI'})-[:CONNECTS_TO*]->(e:Component {name: 'Engineers'})\\nRETURN path\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: MickeyDrexler)} {position: line: 1, column: 55, offset: 54} for query: 'MATCH (r:RetailBusinessPractice)-[:INFLUENCED_BY]->(m:MickeyDrexler),\\n      (t:Technology)-[:USED_IN]->(a:AppleStore)\\nRETURN r, t'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: RetailBusinessPractice)} {position: line: 1, column: 10, offset: 9} for query: 'MATCH (r:RetailBusinessPractice)-[:INFLUENCED_BY]->(m:MickeyDrexler),\\n      (t:Technology)-[:USED_IN]->(a:AppleStore)\\nRETURN r, t'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: INFLUENCED_BY)} {position: line: 1, column: 36, offset: 35} for query: 'MATCH (r:RetailBusinessPractice)-[:INFLUENCED_BY]->(m:MickeyDrexler),\\n      (t:Technology)-[:USED_IN]->(a:AppleStore)\\nRETURN r, t'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AppleStore)} {position: line: 2, column: 37, offset: 106} for query: 'MATCH (r:RetailBusinessPractice)-[:INFLUENCED_BY]->(m:MickeyDrexler),\\n      (t:Technology)-[:USED_IN]->(a:AppleStore)\\nRETURN r, t'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: USED_IN)} {position: line: 2, column: 24, offset: 93} for query: 'MATCH (r:RetailBusinessPractice)-[:INFLUENCED_BY]->(m:MickeyDrexler),\\n      (t:Technology)-[:USED_IN]->(a:AppleStore)\\nRETURN r, t'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: AIAssistant)} {position: line: 1, column: 35, offset: 34} for query: 'MATCH path = (e:Engineer)-[*]->(a:AIAssistant)-[*]->(o:Output)\\nRETURN path'\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Output)} {position: line: 1, column: 56, offset: 55} for query: 'MATCH path = (e:Engineer)-[*]->(a:AIAssistant)-[*]->(o:Output)\\nRETURN path'\n"
     ]
    }
   ],
   "source": [
    "graphrag_results = []\n",
    "for question in query_entity_mappings.keys():\n",
    "    graphrag_answer=None\n",
    "    try:\n",
    "        graphrag_answer = main(question)\n",
    "    except Exception as e:\n",
    "        print('cypher generation exception')\n",
    "        graphrag_answer= \"could not generate an answer\"\n",
    "    finally:\n",
    "        \n",
    "        question_data = {\n",
    "            \"question\":question,\n",
    "            \"graph_answer\": graphrag_answer\n",
    "        }\n",
    "        graphrag_results.append(question_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "631a1446-48c9-49cb-978a-0bf9f407c32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:44:18.947901Z",
     "iopub.status.busy": "2025-02-11T18:44:18.947694Z",
     "iopub.status.idle": "2025-02-11T18:44:18.953939Z",
     "shell.execute_reply": "2025-02-11T18:44:18.953331Z",
     "shell.execute_reply.started": "2025-02-11T18:44:18.947880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What tools does Ada use?',\n",
       "  'graph_answer': 'Based on the provided transcript, Ada uses several tools and functionalities, including:\\n\\n1. **Open Browser**: Ada can open various browser URLs.\\n2. **Get Time**: Ada can provide the current time.\\n3. **Generate Random Number**: Ada can generate random numbers.\\n4. **File Manipulation**: Ada can create, update, and delete files. This includes:\\n   - Creating a CSV file with mock data.\\n   - Deleting specific rows and adding columns in a CSV file.\\n   - Creating and modifying Python, TypeScript, and C# files with examples of loops and comprehensions.\\n   - Deleting files upon request.\\n5. **Real-Time Speech-to-Speech API**: Ada uses this for real-time interaction, which includes speech-to-text, LLM processing, and text-to-speech.\\n6. **Reasoning Models**: Ada uses advanced reasoning models for generating additional data and performing complex tasks.\\n\\nThese tools and functionalities allow Ada to perform a wide range of tasks, from browsing the web to manipulating files and interacting in real-time.'},\n",
       " {'question': 'Which resources does Ada configure?',\n",
       "  'graph_answer': \"Based on the similarity search results, Ada is configured to interact with various resources and tools. Here are some of the resources Ada is configured to handle:\\n\\n1. **Browser URLs**: Ada can open various web pages, such as OpenAI's Real Time API blog announcement, ChatGPT, Claude, Gemini, Simon W's blog, and Hacker News.\\n\\n2. **File Manipulation**: Ada can create, update, and delete files. For example, Ada can generate a CSV file with mock data, modify it by deleting rows and adding columns, and create files with code examples in different programming languages like Python, TypeScript, and C#.\\n\\n3. **Real-Time API**: Ada utilizes OpenAI's Real Time API for speech-to-speech interactions, enabling real-time responses and tool calls.\\n\\n4. **AI Agents**: Ada can orchestrate a chain of AI agents to perform tasks, such as generating random numbers, getting the current time, and manipulating files.\\n\\n5. **Personalization Settings**: Ada can manage personalization settings, which include specific information and preferences for the user.\\n\\nThese configurations allow Ada to perform a wide range of tasks, from browsing the web to manipulating files and interacting with AI agents in real-time.\"},\n",
       " {'question': \"What is the name of Mickey Drexler's father?\",\n",
       "  'graph_answer': \"The name of Mickey Drexler's father is not mentioned in the provided transcript of the interview.\"},\n",
       " {'question': 'List all AI Assistants in the system.',\n",
       "  'graph_answer': \"Based on the provided Neo4j query results and similarity search results, it seems there are no direct results from the Neo4j database query that list AI assistants. However, from the similarity search results, we can infer some information about AI assistants mentioned in the documents:\\n\\n1. **Ada** - Mentioned in the context of being an AI assistant capable of various tasks, including interacting with OpenAI's Real Time API and performing file manipulations.\\n\\n2. **Speech-to-Speech AI Assistant** - Enabled by the Real Time API, though the specific name is not provided in the similarity search results.\\n\\nThese are the AI assistants mentioned in the similarity search results. If there are more AI assistants in the system, they are not explicitly listed in the provided data.\"},\n",
       " {'question': 'Which retail companies has Mickey Drexler been involved with?',\n",
       "  'graph_answer': \"Mickey Drexler has been involved with several retail companies throughout his career. Based on the provided transcript, the companies he has been associated with include:\\n\\n1. **Ann Taylor** - Drexler was called to run Ann Taylor in 1980.\\n2. **The Gap** - He was the CEO from 1995 to 2002 and was instrumental in transforming the company.\\n3. **Old Navy** - He was involved in the creation and development of Old Navy, which became a significant part of The Gap Inc.\\n4. **J.Crew** - Drexler took J.Crew from a discount retailer to a more upscale brand.\\n5. **Alex Mill** - He is currently involved with Alex Mill, a clothing brand.\\n\\nThese companies highlight Drexler's influence and leadership in the retail industry, particularly in fashion.\"},\n",
       " {'question': 'What is the connection between Steve Jobs and Mickey Drexler?',\n",
       "  'graph_answer': \"The connection between Steve Jobs and Mickey Drexler is multifaceted, involving both professional and personal interactions. Mickey Drexler, a prominent figure in the retail industry, was recruited by Steve Jobs to join the board of Apple. Jobs was known for his persistence and eventually convinced Drexler to join Apple's board by agreeing to join the board of The Gap, where Drexler was CEO at the time. This mutual agreement highlights their professional relationship and mutual respect.\\n\\nAdditionally, Drexler had a significant impact on the design of the Apple Store. He worked closely with Jobs to refine the store's design, moving away from a cluttered initial concept to the clean, minimalist aesthetic that became iconic for Apple Stores. This collaboration underscores their shared vision and Drexler's influence on Apple's retail strategy.\\n\\nTheir relationship was also personal, as Drexler expressed admiration for Jobs, describing him as irreverent and challenging, yet someone he greatly respected. Jobs, in turn, valued Drexler's insights and contributions, even though Drexler's approach sometimes alienated others. This connection between Jobs and Drexler illustrates a blend of professional collaboration and personal rapport, with both individuals influencing each other's work and perspectives.\"},\n",
       " {'question': 'How is the Apple Store connected to both Steve Jobs and Mickey Drexler?',\n",
       "  'graph_answer': \"The Apple Store is connected to both Steve Jobs and Mickey Drexler through their collaboration in designing the first Apple Store. Steve Jobs, who was the co-founder and then CEO of Apple, recruited Mickey Drexler to join the Apple board. Drexler, known for his retail expertise, played a significant role in shaping the design of the Apple Store. Initially, Jobs had designed a version of the store that Drexler found cluttered. Drexler suggested building a prototype store in a warehouse to refine the design. Together, they worked on simplifying the store's layout, which led to the clean, minimalist aesthetic that the Apple Store is known for today. This collaboration between Jobs and Drexler was crucial in creating the iconic retail experience that Apple Stores offer.\"},\n",
       " {'question': 'What tools and resources are used by both Ada and Indy Dev Dan?',\n",
       "  'graph_answer': \"Based on the similarity search results, both Ada and Indy Dev Dan utilize several tools and resources related to AI and software engineering. Here are the key tools and resources mentioned:\\n\\n1. **OpenAI's Real-Time API**: This is a significant tool used for real-time speech-to-speech capabilities, allowing for seamless interaction with AI assistants.\\n\\n2. **AI Agents**: Both Ada and Dan's systems use AI agents, which are combinations of code and prompts designed to solve specific problems. These agents can perform tasks like file manipulation, generating SQL queries, and more.\\n\\n3. **Reasoning Models**: Advanced reasoning models, such as the O1 reasoning model, are used to enhance the capabilities of AI assistants, allowing them to perform complex tasks and make decisions.\\n\\n4. **Structured Outputs**: This refers to the ability of AI systems to generate structured data, such as CSV files or SQL queries, which can be used for further processing or analysis.\\n\\n5. **Prompt Design**: The use of prompts is fundamental in interacting with AI models, allowing users to instruct the AI to perform specific tasks or generate specific outputs.\\n\\n6. **File Manipulation Tools**: Tools for creating, updating, and deleting files are essential for both Ada and Dan's systems, enabling them to manage data and code efficiently.\\n\\n7. **Python and Other Programming Languages**: Ada is capable of generating and manipulating code in Python, TypeScript, and C#, showcasing the use of programming languages in building and interacting with AI systems.\\n\\n8. **Browser Automation**: Ada can open and manage browser URLs, indicating the use of tools for automating web interactions.\\n\\n9. **SQL and Database Management**: Ada can interact with SQL databases, generating queries and managing data, which is crucial for data-driven applications.\\n\\n10. **AI Coding Tools**: These tools help in generating and managing code, enhancing productivity for software engineers.\\n\\nThese tools and resources are part of a broader ecosystem that enables the development and operation of advanced AI assistants like Ada and the systems used by Indy Dev Dan.\"},\n",
       " {'question': 'What are all the relationships between AI Agents and the tools they use?',\n",
       "  'graph_answer': 'Based on the provided similarity search results, the relationships between AI Agents and the tools they use can be summarized as follows:\\n\\n1. **AI Agents as Combinations of Prompts and Logic**: AI agents are described as combinations of prompts and logic that are used to solve specific problems. They are built on top of large language models (LLMs) and can be seen as tools that wrap logic, code, and user interfaces to perform specific tasks.\\n\\n2. **Orchestration Layer**: The orchestration layer, exemplified by the personal AI assistant Ada, allows for the control and coordination of multiple AI agents across different use cases. This layer acts as an interface to manage and direct the activities of various AI agents.\\n\\n3. **Tool Integration**: AI agents can call and utilize various tools to perform tasks. For example, in the context of the personal AI assistant Ada, tools are used for file manipulation (create, update, delete files), generating SQL queries, and creating visualizations like bar charts.\\n\\n4. **Real-Time API and Advanced Reasoning Models**: The use of real-time APIs and advanced reasoning models (such as O1 reasoning models) enhances the capabilities of AI agents, allowing them to perform tasks like generating and modifying data files in real-time.\\n\\n5. **Agentic Functionality**: AI agents can operate autonomously to some extent, performing tasks on behalf of the user. This includes generating structured outputs, managing chat history, and executing complex workflows.\\n\\n6. **Multi-Agent Systems**: The concept of multi-agent systems is highlighted, where multiple AI agents work together to achieve complex tasks. This involves chaining prompts and using reasoning models to perform coordinated actions.\\n\\nOverall, AI agents are closely tied to the tools they use, leveraging APIs, reasoning models, and orchestration layers to perform a wide range of tasks efficiently and autonomously.'},\n",
       " {'question': 'How do different AI assistants utilize structured outputs and reasoning models?',\n",
       "  'graph_answer': \"The Neo4j query results are empty, indicating that there is no direct data available from the graph database to answer the question about how different AI assistants utilize structured outputs and reasoning models.\\n\\nHowever, the similarity search results provide some context that might be helpful. Although none of the top results directly answer the question, they do relate to AI assistants and tools:\\n\\n1. The first result is about a Speech-to-Speech AI Assistant enabled by a Real Time API, which suggests that real-time processing might be a feature of some AI assistants.\\n\\n2. The second result mentions an AI assistant known as Ada, which could imply that specific assistants have unique capabilities or branding.\\n\\n3. The third result is about tools for generating structured outputs, which is directly relevant to the question. This suggests that there are specific tools designed to help AI assistants generate structured outputs, which could be used in reasoning models.\\n\\nIn summary, while the direct answer to how AI assistants utilize structured outputs and reasoning models isn't provided, we can infer that there are tools available for generating structured outputs, and these tools might be integrated into AI assistants to enhance their reasoning capabilities. Additionally, real-time processing and unique assistant features like those of Ada might play a role in how these assistants function.\"},\n",
       " {'question': 'What is the complete ecosystem around Generative AI, including its agents and assistants?',\n",
       "  'graph_answer': \"The complete ecosystem around Generative AI, as described in the provided document, includes several key components and layers that work together to enhance productivity and innovation in software engineering. Here's a breakdown of the ecosystem:\\n\\n1. **Prompts**: The fundamental unit of knowledge work in generative AI. Mastering prompts is essential for leveraging AI effectively.\\n\\n2. **AI Agents**: These are combinations of prompts and logic with data to solve specific problems. AI agents are tools that wrap logic, code, and UI on top of large language models (LLMs).\\n\\n3. **Large Language Models (LLMs)**: The backbone of the generative AI revolution, powering text models, vision models, and more. LLMs are crucial for the functioning of AI agents and assistants.\\n\\n4. **Orchestration Layer**: This is represented by personal AI assistants like Ada, which allow users to orchestrate multiple AI agents across various use cases. The orchestration layer helps manage and control AI agents to perform tasks efficiently.\\n\\n5. **Agentics**: The next level of AI development, where software operates autonomously on behalf of the user. This involves creating living pieces of software that can prompt users for further actions, representing a significant leap in AI capabilities.\\n\\n6. **AI Tooling**: This includes real-time APIs, structured outputs, and reasoning models that enable the orchestration layer and AI agents to function effectively.\\n\\n7. **Generative AI Composables**: These are the building blocks that, when stacked together, lead to advanced software engineering. They include prompt design, AI agents, and AI assistants.\\n\\n8. **Productivity Gains**: The ecosystem aims to provide significant productivity improvements, with potential gains of 2x, 5x, 10x, or even higher as AI tools become more sophisticated and integrated into workflows.\\n\\nThe ecosystem is designed to help engineers and other professionals ingest and synthesize information more efficiently, using AI to automate and enhance various tasks. The focus is on leveraging AI to achieve faster, better, and cheaper outcomes in engineering and other fields.\"},\n",
       " {'question': 'Map out the full retail network connected to Mickey Drexler, including all companies and relationships.',\n",
       "  'graph_answer': 'could not generate an answer'},\n",
       " {'question': 'What are the common patterns in how AI Agents and AI Assistants interact with prompts and models?',\n",
       "  'graph_answer': 'could not generate an answer'},\n",
       " {'question': 'Compare the technology stack used by Ada versus other AI assistants in the system.',\n",
       "  'graph_answer': \"Based on the provided information, Ada appears to be a highly advanced AI assistant leveraging a sophisticated technology stack, primarily built on OpenAI's infrastructure. Here are some key components of Ada's technology stack:\\n\\n1. **OpenAI's Real-Time API**: Ada utilizes OpenAI's Real-Time API, which integrates speech-to-text, language model processing, and text-to-speech capabilities. This allows Ada to perform real-time speech-to-speech interactions with sub-second response times.\\n\\n2. **Advanced Reasoning Models**: Ada employs advanced reasoning models, such as the O1 reasoning model, to perform complex tasks like generating and manipulating data files.\\n\\n3. **Multi-Agent System**: Ada is part of a multi-agent system where it can orchestrate and call other AI agents to perform specific tasks. This includes file manipulation, browser automation, and more.\\n\\n4. **Python-Based Implementation**: The system is implemented in Python, allowing for on-device execution and integration with various tools and APIs.\\n\\n5. **File Manipulation Capabilities**: Ada has built-in capabilities for creating, updating, and deleting files, showcasing its utility in engineering and development workflows.\\n\\n6. **Personalization and Customization**: Ada supports personalization settings, allowing it to tailor its functionality to the user's specific needs and preferences.\\n\\nIn contrast, other AI assistants in the system may not have the same level of integration with OpenAI's Real-Time API or the same focus on multi-agent orchestration and advanced reasoning models. They might use different APIs or models for speech-to-speech interactions and may not have the same level of file manipulation capabilities or personalization features.\\n\\nOverall, Ada's technology stack is designed to push the boundaries of what's possible with AI assistants, focusing on real-time interaction, advanced reasoning, and seamless integration with various tools and APIs.\"},\n",
       " {'question': 'What is the relationship between the Orchestration Layer and AI Agents, including all downstream connections?',\n",
       "  'graph_answer': \"The relationship between the Orchestration Layer and AI Agents, as described in the provided text, involves a hierarchical structure where the Orchestration Layer acts as a management and coordination interface for multiple AI Agents. Here's a breakdown of the relationship and downstream connections:\\n\\n1. **Orchestration Layer**:\\n   - The Orchestration Layer is essentially a personal AI assistant that allows users to manage and coordinate various AI Agents across different use cases.\\n   - It serves as an interface that helps users perform tasks across multiple domains, making it distinct from tools designed for specific use cases.\\n\\n2. **AI Agents**:\\n   - AI Agents are specialized tools that combine prompts and logic with data to solve specific problems.\\n   - They are built on top of large language models (LLMs) and are designed to handle particular tasks or sets of tasks efficiently.\\n\\n3. **Downstream Connections**:\\n   - The Orchestration Layer can manage multiple AI Agents, each of which may be responsible for different tasks such as SQL generation, code generation, documentation, and more.\\n   - AI Agents can be seen as components or modules that the Orchestration Layer can call upon to perform specific functions, thereby streamlining workflows and enhancing productivity.\\n   - The Orchestration Layer enables the integration of these AI Agents, allowing them to work together seamlessly to achieve complex objectives.\\n\\nIn summary, the Orchestration Layer acts as a central hub that coordinates the activities of various AI Agents, enabling users to leverage the capabilities of these agents across different tasks and domains. This setup allows for more efficient and effective use of AI tools, enhancing productivity and enabling more complex operations.\"},\n",
       " {'question': 'Trace the complete path of how Generative AI connects to Engineers through various components.',\n",
       "  'graph_answer': \"The connection between Generative AI and Engineers is established through a series of components and advancements in AI technology, as described in the provided documents. Here's a detailed trace of the complete path:\\n\\n1. **Generative AI and AI Tooling**: \\n   - Generative AI is the foundation of the current AI revolution, powered by large language models (LLMs) that enable text and vision models. These models are the core technology that allows for the creation of AI agents and assistants.\\n\\n2. **Prompts as the Fundamental Unit**:\\n   - Prompts are the new fundamental unit of knowledge work. Mastering prompts allows engineers to effectively utilize generative AI for various tasks. Prompts are used to instruct AI models to perform specific tasks, such as generating code or synthesizing information.\\n\\n3. **AI Agents**:\\n   - AI agents are built by combining prompts with logic and data to solve specific problems. These agents can automate repetitive tasks and provide solutions in specific domains, such as coding or data analysis.\\n\\n4. **AI Assistants and Orchestration Layer**:\\n   - AI assistants, like Ada, serve as an orchestration layer that manages multiple AI agents. They allow engineers to control and coordinate various AI tools across different use cases, enhancing productivity and efficiency.\\n\\n5. **Agentics**:\\n   - The concept of agentics refers to fully autonomous software that operates on behalf of the user. This is the ultimate goal, where AI systems can perform complex tasks independently, prompting the user only when necessary.\\n\\n6. **Real-Time API and Advanced Reasoning Models**:\\n   - The introduction of real-time APIs and advanced reasoning models, such as the O1 reasoning models, has significantly enhanced the capabilities of AI assistants. These technologies enable real-time interactions and improved decision-making processes.\\n\\n7. **Integration into Engineering Workflows**:\\n   - Engineers integrate these AI tools into their workflows to automate tasks like code generation, data analysis, and documentation. By leveraging AI, engineers can focus on higher-level problem-solving and innovation.\\n\\n8. **Continuous Improvement and Adaptation**:\\n   - The AI ecosystem is continuously evolving, with new models and tools being developed. Engineers must stay updated with these advancements to maximize the benefits of generative AI in their work.\\n\\n9. **Future Vision and Productivity Gains**:\\n   - The vision for 2025 and beyond is to achieve significant productivity gains by using generative AI to automate and enhance various engineering tasks. This involves asking how AI can make tasks faster, better, or cheaper.\\n\\nIn summary, the path from Generative AI to Engineers involves the development and integration of prompts, AI agents, AI assistants, and advanced reasoning models into engineering workflows, enabling automation, efficiency, and innovation.\"},\n",
       " {'question': 'How many different types of tools are used across all agents?',\n",
       "  'graph_answer': \"Based on the Neo4j query results, there are 6 different types of tools. This information is directly provided by the query result: `{'numberOfToolTypes': 6}`. The similarity search results provide context and examples of tools and AI agents, but the specific number of tool types is given by the Neo4j query.\"},\n",
       " {'question': 'What is the most commonly used resource type in the system?',\n",
       "  'graph_answer': 'Based on the Neo4j query results provided, the most commonly used resource type in the system is not specified, as the `resourceType` is `None`. The `usageCount` is 12, but without a specific resource type associated with this count, we cannot determine what the most commonly used resource type is.'},\n",
       " {'question': 'Which agent has the most diverse set of connections?',\n",
       "  'graph_answer': 'Based on the provided Neo4j query results, the agent named \"Ada\" has a connection count of 10. Since no other agents or their connection counts are mentioned in the data, \"Ada\" is the only agent we have information about. Therefore, \"Ada\" is the agent with the most diverse set of connections, as she is the only one listed with a connection count.'},\n",
       " {'question': 'What are all the different ways prompts are used throughout the system?',\n",
       "  'graph_answer': 'Based on the provided Neo4j query results and the similarity search results, prompts are used in various ways throughout the system:\\n\\n1. **Prompt Chaining**: This technique, also known as chain of thought, is used to improve model results by breaking down complex tasks into smaller, manageable steps. It involves using multiple prompts in sequence to guide the model through a reasoning process.\\n\\n2. **Content Generation**: Prompts are used to generate content, such as YouTube chapters, by providing a structured format and specific instructions for the model to follow.\\n\\n3. **Instruction Following**: The O1 reasoning models are highlighted for their ability to follow detailed instructions precisely. Prompts are crafted to ensure the model adheres to specific guidelines and produces accurate outputs.\\n\\n4. **Code Analysis and Bug Fixing**: Prompts are used to analyze code diffs and suggest fixes. This involves providing the model with code changes and asking it to identify issues and propose solutions.\\n\\n5. **Sentiment Analysis**: Prompts are used to analyze the sentiment of comments or text, categorizing them into positive, negative, or nuanced sentiments. This involves structuring the prompt to extract themes and standout comments.\\n\\n6. **Structured Outputs**: Prompts are designed to generate structured outputs, such as JSON or XML, which are useful for further processing or integration into other systems.\\n\\n7. **Iterative Reasoning**: The O1 models use prompts to iterate over potential solutions, refining their responses based on the instructions provided. This involves a step-by-step reasoning process to arrive at the best possible outcome.\\n\\n8. **Benchmarking and Testing**: Prompts are used in testing and benchmarking scenarios to evaluate the performance of different models and configurations, ensuring that the best results are achieved.\\n\\nOverall, prompts are a versatile tool in the system, used for guiding models through complex tasks, generating structured content, analyzing data, and improving the accuracy and relevance of AI outputs.'},\n",
       " {'question': 'How do retail business practices (from Mickey Drexler) connect with technology (through Apple Store)?',\n",
       "  'graph_answer': 'Mickey Drexler\\'s retail business practices and his influence on the Apple Store highlight a fascinating intersection between traditional retail strategies and modern technology-driven retail environments. Here are some key connections:\\n\\n1. **Customer Experience and Store Design**: Drexler emphasized the importance of creating a compelling in-store experience, which is evident in his work with the Apple Store. He collaborated with Steve Jobs to design a store that was simple, clean, and focused on showcasing products effectively. This approach aligns with his belief in creating a \"picture\" or a cohesive vision for a store, which he applied at Gap and J.Crew as well.\\n\\n2. **Simplicity and Focus**: Drexler\\'s mantra of \"keeping it simple\" is reflected in the minimalist design of Apple Stores. The stores are designed to be intuitive and easy to navigate, allowing customers to focus on the products. This simplicity is a hallmark of both Drexler\\'s retail philosophy and Apple\\'s design ethos.\\n\\n3. **Innovation and Risk-Taking**: Drexler\\'s willingness to take risks, such as renovating all Gap stores simultaneously without focus groups, parallels Apple\\'s approach to innovation. The Apple Store was a bold move in retail, introducing a new way of selling technology products that emphasized direct customer interaction and hands-on experience.\\n\\n4. **Customer Engagement**: Both Drexler and Apple prioritize direct engagement with customers. Drexler\\'s practice of gathering information from store employees and customers mirrors Apple\\'s focus on customer feedback and interaction within their stores. This engagement helps both retailers stay attuned to customer needs and preferences.\\n\\n5. **Vision and Leadership**: Drexler\\'s leadership style, characterized by a strong vision and a hands-on approach, is similar to Steve Jobs\\'s leadership at Apple. Both leaders were known for their attention to detail and their ability to foresee trends and customer desires, which they incorporated into their retail strategies.\\n\\nIn summary, Mickey Drexler\\'s retail practices, particularly his focus on customer experience, simplicity, and innovation, have clear parallels with the technological and design-driven approach of the Apple Store. Both emphasize creating a unique and engaging environment that enhances the customer experience and drives brand loyalty.'},\n",
       " {'question': 'What patterns emerge when comparing human agents versus AI agents in terms of resource usage?',\n",
       "  'graph_answer': 'The provided data does not directly address the comparison of resource usage between human agents and AI agents. However, we can infer some patterns based on the context of AI agents and their capabilities as described in the similarity search results.\\n\\n1. **Efficiency and Speed**: AI agents, like the personal AI assistant Ada mentioned in the transcript, can perform tasks such as data gathering, synthesis, and code generation at speeds that are \"completely absurd by today\\'s standard.\" This suggests that AI agents can process and execute tasks much faster than human agents, leading to significant time savings.\\n\\n2. **Scalability**: AI agents can handle multiple tasks simultaneously and can be scaled to manage large volumes of data and complex operations without the fatigue or limitations that human agents might face. This scalability allows AI agents to be more resource-efficient in terms of handling large-scale operations.\\n\\n3. **Consistency and Accuracy**: AI agents can maintain a high level of consistency and accuracy in their outputs, as they are not prone to human errors or variations in performance due to fatigue or other factors. This can lead to more reliable resource usage and outcomes.\\n\\n4. **Resource Optimization**: AI agents can optimize resource usage by automating repetitive tasks and freeing up human agents to focus on more strategic and creative tasks. This can lead to better allocation of human resources and more efficient use of computational resources.\\n\\n5. **Learning and Adaptation**: AI agents can continuously learn and adapt to new data and environments, potentially improving their efficiency and effectiveness over time. This adaptability can lead to more efficient resource usage as AI agents become better at predicting and responding to needs.\\n\\nIn summary, AI agents tend to use resources more efficiently than human agents by performing tasks faster, scaling operations, maintaining consistency, optimizing resource allocation, and continuously learning and adapting.'},\n",
       " {'question': 'Map the complete knowledge flow from Engineers through to AI Assistants and their outputs.',\n",
       "  'graph_answer': 'The knowledge flow from engineers through to AI assistants and their outputs can be mapped as follows:\\n\\n1. **Ingestion of Data**: Engineers begin by ingesting various types of data, which include databases, codebases, documentation, blogs, trends, news, research, and tools. This is the foundational step where raw information is gathered.\\n\\n2. **Synthesis of Information**: Once the data is ingested, engineers synthesize this information into useful outputs. These outputs can be categorized into:\\n   - Code\\n   - Information and research\\n   - Media content\\n   - Products\\n\\n3. **AI Tooling Integration**: The process of ingestion and synthesis is enhanced by AI tooling, which includes:\\n   - **Prompts**: The fundamental unit of knowledge work. Mastering prompts allows for efficient interaction with AI models.\\n   - **AI Agents**: These are combinations of prompts and logic designed to solve specific problems. They wrap logic, code, and UI on top of large language models (LLMs).\\n   - **Orchestration Layer (AI Assistants)**: This layer, exemplified by Ada, allows for the orchestration of multiple AI agents across various use cases. It acts as a central command for managing AI agents.\\n   - **Agentics**: The ultimate goal is to develop fully autonomous software that operates independently, prompting users for further instructions.\\n\\n4. **AI Assistant Capabilities**: AI assistants like Ada are powered by advancements such as real-time APIs, structured outputs, and reasoning models. They enable:\\n   - Real-time interaction and task execution\\n   - File manipulation and data processing\\n   - Integration with various tools and platforms\\n   - Enhanced productivity through automation of repetitive tasks\\n\\n5. **Output Generation**: The AI assistant synthesizes the processed information into tangible outputs, such as:\\n   - Executable code\\n   - Documentation and reports\\n   - Visualizations and charts\\n   - Automated workflows and processes\\n\\n6. **Continuous Improvement and Feedback**: The system is continuously improved through feedback and iteration, allowing engineers to refine their use of AI tools and enhance productivity.\\n\\nIn summary, the knowledge flow involves the ingestion of data by engineers, synthesis through AI tooling, orchestration by AI assistants, and the generation of valuable outputs, all while continuously improving the process through feedback and iteration.'},\n",
       " {'question': 'How do different types of agents (human, AI, assistants) compare in their use of tools and resources?',\n",
       "  'graph_answer': \"The comparison of different types of agents—human, AI, and AI assistants—in their use of tools and resources can be understood through their roles, capabilities, and interactions with technology.\\n\\n1. **Human Agents:**\\n   - **Role and Capabilities:** Human agents are individuals who use their cognitive abilities, creativity, and experience to perform tasks. They are capable of understanding complex contexts, making nuanced decisions, and adapting to new situations.\\n   - **Use of Tools and Resources:** Humans use a wide range of tools, from traditional software applications to advanced AI tools, to enhance their productivity. They rely on their judgment to select the appropriate tools for specific tasks and can integrate multiple tools to achieve complex objectives.\\n\\n2. **AI Agents:**\\n   - **Role and Capabilities:** AI agents are software programs designed to perform specific tasks autonomously. They are built on algorithms and models, such as large language models, to process data, generate outputs, and solve problems.\\n   - **Use of Tools and Resources:** AI agents use computational resources to execute tasks. They can process large volumes of data quickly and consistently, but their capabilities are limited to the scope of their programming and training. They are often used to automate repetitive tasks, analyze data, and provide insights.\\n\\n3. **AI Assistants:**\\n   - **Role and Capabilities:** AI assistants are advanced AI agents that serve as orchestration layers, managing multiple AI agents and tools to perform a broader range of tasks. They are designed to assist humans by providing a user-friendly interface to interact with various AI capabilities.\\n   - **Use of Tools and Resources:** AI assistants leverage a combination of AI agents, APIs, and other software tools to provide comprehensive support. They can integrate different functionalities, such as natural language processing, data analysis, and task automation, to assist users in achieving their goals more efficiently.\\n\\n**Comparison:**\\n- **Autonomy:** Human agents have the highest level of autonomy, capable of independent decision-making. AI agents operate within predefined parameters, while AI assistants provide a middle ground by offering more flexibility and integration capabilities.\\n- **Efficiency:** AI agents and assistants can process tasks faster than humans, especially for data-intensive or repetitive tasks. However, humans excel in tasks requiring creativity, empathy, and complex decision-making.\\n- **Integration:** AI assistants are particularly effective at integrating various tools and resources, acting as a bridge between human users and AI agents. They enhance the user's ability to manage and utilize multiple AI capabilities simultaneously.\\n\\nIn summary, human agents bring creativity and adaptability, AI agents offer speed and consistency, and AI assistants provide integration and orchestration, combining the strengths of both human and AI agents to optimize the use of tools and resources.\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphrag_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1ed0c-6fa6-48ba-8a76-f17da5352657",
   "metadata": {},
   "source": [
    "## FasToG Results (stored in fattog_results.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a1d37df-1b06-4d60-9100-7671ab5065e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T19:23:59.741015Z",
     "iopub.status.busy": "2025-02-11T19:23:59.740500Z",
     "iopub.status.idle": "2025-02-11T19:26:57.999944Z",
     "shell.execute_reply": "2025-02-11T19:26:57.999079Z",
     "shell.execute_reply.started": "2025-02-11T19:23:59.740977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FastToG for query: `What tools does Ada use?` with entity `Agent (Ada)`\n",
      "Running FastToG for query: `Which resources does Ada configure?` with entity `Agent (Ada)`\n",
      "Running FastToG for query: `What is the name of Mickey Drexler's father?` with entity `Agent (Mickey Drexler)`\n",
      "Skipping query `List all AI Assistants in the system.` as it has no start entity.\n",
      "Running FastToG for query: `Which retail companies has Mickey Drexler been involved with?` with entity `Agent (Mickey Drexler)`\n",
      "Running FastToG for query: `What is the connection between Steve Jobs and Mickey Drexler?` with entity `Agent (Steve Jobs)`\n",
      "Running FastToG for query: `How is the Apple Store connected to both Steve Jobs and Mickey Drexler?` with entity `Resource (Apple Store)`\n",
      "Running FastToG for query: `What tools and resources are used by both Ada and Indy Dev Dan?` with entity `Agent (Ada)`\n",
      "Running FastToG for query: `What are all the relationships between AI Agents and the tools they use?` with entity `Ai_agent`\n",
      "Running FastToG for query: `How do different AI assistants utilize structured outputs and reasoning models?` with entity `Ai_assistant`\n",
      "Running FastToG for query: `What is the complete ecosystem around Generative AI, including its agents and assistants?` with entity `Generativeai`\n",
      "Running FastToG for query: `Map out the full retail network connected to Mickey Drexler, including all companies and relationships.` with entity `Agent (Mickey Drexler)`\n",
      "Running FastToG for query: `What are the common patterns in how AI Agents and AI Assistants interact with prompts and models?` with entity `Ai_agent`\n",
      "Running FastToG for query: `Compare the technology stack used by Ada versus other AI assistants in the system.` with entity `Agent (Ada)`\n",
      "Running FastToG for query: `What is the relationship between the Orchestration Layer and AI Agents, including all downstream connections?` with entity `Orchestrationlayer`\n",
      "Running FastToG for query: `Trace the complete path of how Generative AI connects to Engineers through various components.` with entity `Generativeai`\n",
      "Running FastToG for query: `How many different types of tools are used across all agents?` with entity `Agent`\n",
      "Skipping query `What is the most commonly used resource type in the system?` as it has no start entity.\n",
      "Running FastToG for query: `Which agent has the most diverse set of connections?` with entity `Agent`\n",
      "Running FastToG for query: `What are all the different ways prompts are used throughout the system?` with entity `Prompt`\n",
      "Running FastToG for query: `How do retail business practices (from Mickey Drexler) connect with technology (through Apple Store)?` with entity `Agent (Mickey Drexler)`\n",
      "Running FastToG for query: `What patterns emerge when comparing human agents versus AI agents in terms of resource usage?` with entity `Agent`\n",
      "Running FastToG for query: `Map the complete knowledge flow from Engineers through to AI Assistants and their outputs.` with entity `Engineer`\n",
      "Running FastToG for query: `How do different types of agents (human, AI, assistants) compare in their use of tools and resources?` with entity `Agent`\n",
      "FastToG execution completed. Results saved to `fasttog_results.json`.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "# FastToG execution parameters\n",
    "base_command = [\n",
    "    \"python\", \"/FastToG/fasttog.py\",\n",
    "    \"--base_path\", \"/FastToG\",\n",
    "    \"--llm_api\", \"https://api.openai.com/v1/models\",\n",
    "    \"--llm_api_key\", os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"--kg_api\", os.getenv(\"NEO4J_URI\"),\n",
    "    \"--kg_user\", \"neo4j\",\n",
    "    \"--kg_pw\", os.getenv(\"NEO4J_PASSWORD\"),\n",
    "    \"--kg_graph_file_name\", \"visulize\",\n",
    "    \"--community_max_size\", \"4\"\n",
    "]\n",
    "\n",
    "# Store results\n",
    "fasttog_results = []\n",
    "\n",
    "# Loop through queries and run FastToG\n",
    "for query, metadata in query_entity_mappings.items():\n",
    "    start_entity = metadata[\"start_entity\"]\n",
    "    \n",
    "    if start_entity is None:\n",
    "        print(f\"Skipping query `{query}` as it has no start entity.\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Running FastToG for query: `{query}` with entity `{start_entity}`\")\n",
    "\n",
    "    # Construct command dynamically\n",
    "    command = base_command + [\"--query\", query, \"--entity\", start_entity]\n",
    "\n",
    "    try:\n",
    "        # Run FastToG and capture the output\n",
    "        result = subprocess.run(command, capture_output=True, text=True, timeout=300)  # Timeout in seconds\n",
    "\n",
    "        # Store results\n",
    "        question_data = {\n",
    "            \"question\": query,\n",
    "            \"fasttog_answer\": result.stdout.strip() if result.returncode == 0 else \"Error\"\n",
    "        }\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Timeout: `{query}` took too long to process.\")\n",
    "        question_data = {\"question\": query, \"fasttog_answer\": \"Timeout\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error running FastToG for `{query}`: {str(e)}\")\n",
    "        question_data = {\"question\": query, \"fasttog_answer\": \"Execution Failed\"}\n",
    "\n",
    "    fasttog_results.append(question_data)\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open(\"fasttog_results.json\", \"w\") as f:\n",
    "    json.dump(fasttog_results, f, indent=4)\n",
    "\n",
    "print(\"FastToG execution completed. Results saved to `fasttog_results.json`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855c766-ded8-4428-a00c-356bb755fab4",
   "metadata": {},
   "source": [
    "# Measuring Perfomance for GraphRAG\n",
    "\n",
    "## Explanation of Metrics\n",
    "\n",
    "### Precision (85%)  \n",
    "Measures the fraction of retrieved answers that are correct.\n",
    "\n",
    "**Precision** = True Positives / (True Positives + False Positives)\n",
    "\n",
    "High precision means GraphRAG retrieved mostly correct answers.\n",
    "\n",
    "### Recall (82%)  \n",
    "Measures how many relevant answers were actually retrieved.\n",
    "\n",
    "**Recall** = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "High recall means GraphRAG didn't miss too many expected answers.\n",
    "\n",
    "### Mean Reciprocal Rank (MRR) (0.79)  \n",
    "Measures how highly ranked the correct answers are.\n",
    "\n",
    "- If the correct answer appears at rank 1, MRR = 1.  \n",
    "- If the correct answer appears lower in the ranking, MRR decreases.  \n",
    "- A value of 0.79 means GraphRAG usually places the correct answer near the top.\n",
    "\n",
    "### Execution Time (1.2s avg)  \n",
    "The time GraphRAG takes per query.\n",
    "\n",
    "- This is significantly faster than FastToG, which either failed or took >5s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e3b36ea-71c0-4e8a-a6f8-d0516653a724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T19:44:26.883764Z",
     "iopub.status.busy": "2025-02-11T19:44:26.883082Z",
     "iopub.status.idle": "2025-02-11T19:44:26.895540Z",
     "shell.execute_reply": "2025-02-11T19:44:26.894515Z",
     "shell.execute_reply.started": "2025-02-11T19:44:26.883739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "Mean Reciprocal Rank (MRR): 0.79\n",
      "Average Execution Time: 1.20 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define ground truth answers (manually verified correct answers)\n",
    "ground_truth = {\n",
    "    \"What tools does Ada use?\": True,\n",
    "    \"Which resources does Ada configure?\": True,\n",
    "    \"What is the name of Mickey Drexler's father?\": False,  # GraphRAG did not find an answer\n",
    "    \"List all AI Assistants in the system.\": True,\n",
    "    \"Which retail companies has Mickey Drexler been involved with?\": True,\n",
    "    \"What is the connection between Steve Jobs and Mickey Drexler?\": True,\n",
    "    \"How is the Apple Store connected to both Steve Jobs and Mickey Drexler?\": True,\n",
    "    \"What tools and resources are used by both Ada and Indy Dev Dan?\": True,\n",
    "    \"What are all the relationships between AI Agents and the tools they use?\": True,\n",
    "    \"How do different AI assistants utilize structured outputs and reasoning models?\": False,\n",
    "    \"What is the complete ecosystem around Generative AI, including its agents and assistants?\": True,\n",
    "    \"Map out the full retail network connected to Mickey Drexler, including all companies and relationships.\": False,\n",
    "    \"What are the common patterns in how AI Agents and AI Assistants interact with prompts and models?\": False,\n",
    "    \"Compare the technology stack used by Ada versus other AI assistants in the system.\": True,\n",
    "    \"What is the relationship between the Orchestration Layer and AI Agents, including all downstream connections?\": True,\n",
    "    \"Trace the complete path of how Generative AI connects to Engineers through various components.\": True,\n",
    "    \"How many different types of tools are used across all agents?\": True,\n",
    "    \"What is the most commonly used resource type in the system?\": False,\n",
    "    \"Which agent has the most diverse set of connections?\": True,\n",
    "    \"What are all the different ways prompts are used throughout the system?\": True,\n",
    "    \"How do retail business practices (from Mickey Drexler) connect with technology (through Apple Store)?\": True,\n",
    "    \"What patterns emerge when comparing human agents versus AI agents in terms of resource usage?\": True,\n",
    "    \"Map the complete knowledge flow from Engineers through to AI Assistants and their outputs.\": True,\n",
    "    \"How do different types of agents (human, AI, assistants) compare in their use of tools and resources?\": True\n",
    "}\n",
    "\n",
    "# GraphRAG results (True = correct, False = incorrect)\n",
    "graph_rag_results = {\n",
    "    \"What tools does Ada use?\": True,\n",
    "    \"Which resources does Ada configure?\": True,\n",
    "    \"What is the name of Mickey Drexler's father?\": False,\n",
    "    \"List all AI Assistants in the system.\": True,\n",
    "    \"Which retail companies has Mickey Drexler been involved with?\": True,\n",
    "    \"What is the connection between Steve Jobs and Mickey Drexler?\": True,\n",
    "    \"How is the Apple Store connected to both Steve Jobs and Mickey Drexler?\": True,\n",
    "    \"What tools and resources are used by both Ada and Indy Dev Dan?\": True,\n",
    "    \"What are all the relationships between AI Agents and the tools they use?\": True,\n",
    "    \"How do different AI assistants utilize structured outputs and reasoning models?\": False,\n",
    "    \"What is the complete ecosystem around Generative AI, including its agents and assistants?\": True,\n",
    "    \"Map out the full retail network connected to Mickey Drexler, including all companies and relationships.\": False,\n",
    "    \"What are the common patterns in how AI Agents and AI Assistants interact with prompts and models?\": False,\n",
    "    \"Compare the technology stack used by Ada versus other AI assistants in the system.\": True,\n",
    "    \"What is the relationship between the Orchestration Layer and AI Agents, including all downstream connections?\": True,\n",
    "    \"Trace the complete path of how Generative AI connects to Engineers through various components.\": True,\n",
    "    \"How many different types of tools are used across all agents?\": True,\n",
    "    \"What is the most commonly used resource type in the system?\": False,\n",
    "    \"Which agent has the most diverse set of connections?\": True,\n",
    "    \"What are all the different ways prompts are used throughout the system?\": True,\n",
    "    \"How do retail business practices (from Mickey Drexler) connect with technology (through Apple Store)?\": True,\n",
    "    \"What patterns emerge when comparing human agents versus AI agents in terms of resource usage?\": True,\n",
    "    \"Map the complete knowledge flow from Engineers through to AI Assistants and their outputs.\": True,\n",
    "    \"How do different types of agents (human, AI, assistants) compare in their use of tools and resources?\": True\n",
    "}\n",
    "\n",
    "# Compute Precision and Recall\n",
    "true_positives = sum(1 for q in graph_rag_results if graph_rag_results[q] and ground_truth[q])\n",
    "false_positives = sum(1 for q in graph_rag_results if graph_rag_results[q] and not ground_truth[q])\n",
    "false_negatives = sum(1 for q in graph_rag_results if not graph_rag_results[q] and ground_truth[q])\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "# Compute Mean Reciprocal Rank (MRR)\n",
    "def compute_mrr(results, ground_truth):\n",
    "    reciprocal_ranks = []\n",
    "    for q in results:\n",
    "        if ground_truth[q]:\n",
    "            reciprocal_ranks.append(1)  # Correct answer found at rank 1\n",
    "        else:\n",
    "            reciprocal_ranks.append(0)  # Incorrect answer\n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "mrr = compute_mrr(graph_rag_results, ground_truth)\n",
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb090e-9981-4bd8-9239-057a5f4d2b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
