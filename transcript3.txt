In this video, I want to share my current vision of the future of engineering with you. This is my plan for how to win in 2025. In this vision, you and I willed generative AI, AI agents, and AI assistants to gather data, synthesize it, and build at rates that are completely absurd by today's standard. There are four key advancements in AI tooling that occurred this year that's unlocked the path to next generation AI engineering. Sonic 3.5, structured outputs, O1 reasoning models, and of course the real-time API. Before we discuss the future of engineering, let me share version 3 of Ada, the personal AI assistant for engineering we've been building up on the channel. Hey Ada. Hi there. How can I help? Go ahead and pull in our SQL tables into your active memory. Tables loaded into memory. Ada, create a markdown document and inside of it just lay out our table definitions. Sure, I'll get started on the markdown document. Markdown document created. Now, Chef Ada, go ahead and select all of our products, order descending by price. SQL query saved to file. Great Aida, go ahead and execute that and generate a CSV file for us. Query executed. Results saved as CSV. Ada generate the SQL for our top 10 products with the highest average rating. Create a CSV file for us. Top 10 products with highest average rating save the CSV. Wonderful. Ada, can you go ahead and generate a Python? Let's do a bar chart and on the XXIS use our product name on the Y. Show the average rating, please. Python code a bar chart and on the x-axis, use our product name on the Y. Show the average rating, please. Python code for bar chart generated. It's saved in top 10 highest average rating products bar chart, Pwatt. Ada, go ahead and delete that bar chart. p and the Python generation code force delete that. Both files deleted. Get our top 10 products by order volume, sort descending, create a CSV file for us. Top 10 products by order volume saved as CSV. Wonderful, Ada. Go ahead and create a Python chart. Let's do a bar chart of the top 10 products here based on our CSV file. Python code for bar chart generated. It's saved in top 10 products by order volume bar chart. PY. Wonderful. Thanks, Ada. You're welcome. So the personal AI assistant you just saw is powered by the real-time API, structured outputs, and the O1 Rezing model. It showcases a glimpse of how high-performing engineers will maximize their output with compute in 2025 and beyond. Ada and the personal AI assistant are only possible due to key AI tooling breakthroughs that happened this year in 2024. The word on the street is we're going to see one additional release occur as well, likely from Anthropic, but we'll see about that. I think whatever comes out, we've already had the key breakthroughs we need to redesign and rethink how we engineer in 2025. So why are these tools important? What do they unlock? They allow us to continue up-leveling our generative AI composables. The pieces that when you stack them together lead to the next level of software engineering, right? We have prompt design, we have AI agents. We now have the AI assistant, which is effectively our orchestration layer. It allows us to control our AI agents. Eventually that will lead us to full-on agentics, where we'll build an own self-operating software. Over the past two videos, we've been digging into the AI assistant, thanks to the real-time API. This is a massive unlock for in parallel engineering, where your AI assistant can work for you on your behalf while you're accomplishing other tasks. It's a work in progress. There are many things to improve, but it absolutely showcases what the future of engineer can and will look like. Right now, you, myself, and other engineers that watch this channel are likely few of many that realize when you put these breakthroughs together and when you start composing your generative AI pieces from prompts to AI agents to assistants, you start building software in a brand new way as an orchestrator, as a manager, and commander of compute. This is going to be a big theme of software engineering in 2025 if you're looking for those outsize returns and if you're looking for next level productivity as an engineer. The prompt is the new fundamental unit of knowledge work. Never forget this. And yes, you heard that here first. Let's start from scratch. What does it mean to be an engineer, right? This is you, the engineer, and the center. What do we do as engineers? We take data in, we ingest data, and then we synthesize it into some form of output, right? Some artifacts. This is software engineering in its most fundamental form. I've stripped out all the details here. This is what we do. We take an information and we synthesize outputs. Let's dig a little deeper, right? Let's go a layer into this. So data for engineers is typically databases, code bases, documentation, blogs, trends, news, research, tools. It's your job to ingest this information and for your personal work, for your tools, for your career, for your job, is your job to then synthesize everything coming at you into useful output. Let's break down output. This is going to be code, information and research, media content, and products. These are the top four. Of course, there are many other things engineers can build and synthesize. There is some overlap here, but you get the idea, right? Your job as an engineer is to ingest these types of content and then synthesize code, information, research, media, and products. If we simplify what it means to be an engineer, this is what we do. But now things have changed. So as you know, there are hidden layers here in this process for how this ingestion and how this synthesizing actually happens. Now we have AI tooling. So let's break down the AI tooling we can now use to ingest and synthesize information. We now have prompts. This is the new fundamental unit of knowledge work. If you master the prompt, you will master knowledge work, full stop. What's the next level? At the next level, we have AI agents. AIA agents are prompts and logic combined with data to solve a specific problem. If you've been using the latest generation AI coding tools, you're using one or more AI agents, right? That is a tool that wraps logic, code, and UI on top of what? The base level, right? The LLM. The entire revolution that's happening right now is powered entirely by large language models. These are our text models. These are our vision models. This is a generative AI powerhouse. If the LLM did not happen, nothing else happens. Nothing else comes without the LLM. Nothing else comes without the prompt. The AI agents compose one or more prompts to solve a specific problem in a specific system. At the next level, we now have your orchestration layer. This is what we've been working on on the channel over the previous two videos, right? This is AIDA, this is our personal AI assistant. It doesn't need to have speech-to-speech capabilities. It's just a killer fast interface for our orchestration layer. The key differentiation here is that your AI assistant allows you to orchestrate many AI agents across use cases, right? And that's what separates this layer from previous tools. A lot of the tools you're going to see are built with specific use cases built to solve a specific problem. That's great. That's still a wrapper around several AI agents. The orchestration layer or your personal AI assistant is all about helping you do what you need to do across all the domains that you operate in. And then at the last level, we have agentics. So these are full on what I like to call living pieces of software that operate on your behalf while you sleep. A while back I put out a video called the two-way prompt and you know at the end I described this new piece of software, agentic software where you're no longer prompting your AI. It is now prompting you for what it needs to do next, right? It's gotten that good. So this is the last stage. This is where we're going on the channel. This is our North Star. Let me be totally clear. This is, you know, a three, five, 10 year goal and journey. This isn't happening anytime soon. This is insurmountably non-trivial. Okay. So how does that change things, right? How does that tie into my plan for engineering in 2025? It's really this simple. Now you should be asking yourself, given all of my tasks where I'm ingesting and synthesizing, how can I use generative AI to help me do these things faster, better, or cheaper, or all three? Because that's where the real productivity gains really come in. And just to throw some rough estimates on here, utilizing tools that give you access to language models is, you know, relative to each other. You know, that's the first step, right? That's your initial 2x. When you start using specialized agents to solve problems rapidly over and over, that's going to get you to your, you know, your next huge incremental bump, right? And I don't actually know what the scale is. This is just the way I've felt it over time so far, right? This is your 5x. Now this 10x is something I'm still working on, right? I literally just showed you a version of Ada. That gives us an orchestration layer on top of any set of AIA agents. Okay, so this is our orchestration layer. I'm really excited about this. The real-time speech-to-speech, plus reasoning models, plus structured outputs, really enables this, right? For me, the vision is complete for the orchestration layer. And then there's the last level. And, you know, I don't even know if 10x from here is the right amount, if it's 100x. It's probably much higher than that. When you have this fully autonomous being, this fully autonomous piece of software operating on your behalf, it's probably much higher than this. We're saving that for later. This is a more faded outline for a reason. That's the North Star. It's always to keep the North Star in your mind. But realistically, we're focused here. Two, five, ten. These are all attainable productivity gains you can get right now. It's all about asking the question during my ingestion tasks when I'm looking through databases, writing queries, when I'm reading code, trying to determine how to modify this feature or add this new feature to this code base or looking through documentation or gathering information for an architectural decision you need to make, right? It's now about asking yourself the question, how can I best use one of these layers of AI tooling to help me ingest and synthesize? That's really what it's about. Let's look at a concrete example, right? The most obvious example is code generation. This is the lowest possible hanging fruit in the age of generative AI for software engineers. It's definitely one of the most important, but it is so overhyped. It's so insanely overhyped right now. And what are examples of this? Right now, everyone's using cursor, everyone's using Ader, continue Z. It's a really hot space right now. And, you know, this is the, you know, 5x. So if you're using AI code tooling right now, you're in a great spot, right? Because you know what that feels like to be able to write a prompt and generate massive amounts of code. So that is a concrete example of using AI tooling to both ingest and synthesize information. Code generation is incredible, but it's only a small piece of the puzzle as a software engineer. You just saw me working on a mock doc database instance with Ada, be able to quickly read, ingest, and write SQL statements with artifacts in real time very, very quickly. You saw that all happened just now, right? And that's me tapping into this, you know, orchestration layer advantage, right? I was still only effectively using these closely related AI agents, all closely related to SQL generation, right? Like if we crank open that code base, you can see I've got the tools here separated by use case. And so, you know, we used all the SQL database operations. We also use the AI chat history management tools and a few other ones here, right? We use create and update file, of course. You know, what we're doing here is we're starting to tap into these, these cross domain actions where it's not just about writing an SQL statement. It's about reading tables. It's about writing documentation on the tables. It's about understanding the structure of the database. It's about generating multiple versions. It's about generating diagrams and documentation, right? Software engineering is so much more than just writing code. This whole anyone can write code narrative is so overblown. It's very true. Anyone can generate code with AI, but can you build and maintain software that actually produces value for a user, that's a whole different story, right? That's a whole different story. Coding isn't everything. And that's why it's important for you, the engineer, to understand that you need to match up your ingestion tasks with the highest composition level of AI that you possibly can, and then do the same thing when you're synthesizing results, right, and actually outputting your artifacts and your output and your raw content. So what is my plan in 2025 given this setup? My plan is the same as I just describe. I am looking through all of the cases and all the situations where I'm ingesting and synthesizing. And then I'm asking myself, how often do I do this? And how important is it that I have this problem solved at record speeds, record time faster than ever with generative AI? And the more important it is, the more you need to push the problem up this composition chain. If you generate documentation once a month, you're probably cool to just open up chat TPT, run a random ad hoc prompt, and just get the job done. But if you're building new features and your architecting systems on a weekly or daily basis, you probably want a specialized AI agent and more likely an AI assistant to help you accomplish that task, but also closely related tasks right next to it. So you probably want to build or find an entire AI assistant with the right AI agents inside of it to help you accomplish those tasks at a rapid pace, right? And that's what it's really all about. What operations consume the most of your time? And based on that answer, you should be pushing that up this generative AI composition chain. If it's a one-off task, open up Cloud, open up Gemini, open up chat, GPT, fire a prompt off the CLI, right? It doesn't really matter. But as soon as that use case comes back, right? It's just like typical rules of automation. As soon as that happens, I like three times as a pattern, then you should be building a reusable prompt. After that happens, build an AI agent. It can be a script, it can be a small tool, it can be an entire application. But when that problem comes up again and again and again, you should be thinking about automating it, right? And I've listed the most common operations here for software engineers, so it's a good place to start here. We all have to interact with databases. So you should have your SQL, your ORM, your data access layers streamlined by AI tooling, right? Same thing with codebases. You should be able to read, find, fly through codebases with generative AI tooling. You should be able to also consume documentation and understand and grok documentation with AI tooling. It's the same deal here, right? Blogs, trends, news, research, you should be able to filter out the things that don't matter. And while there are so many things that don't matter, there's so much noise in the world. This section here is becoming really, really important for engineering. There's so much noise in the world. This section here is becoming really, really important for engineering. There's so much just garbage coming out right now and, you know, just useless echo chambering type information is really important to, you know, filter out, you know, get good, reliable channels of information. So, so cut up each one of those ingestion use cases. See how often you do them. The more often, the more important they are. You should be delegating these items out to your slew of prompts, AI agents, and soon, hopefully, AI assistant. Same thing on the synthesizing step, right? The most common things we do as engineers, we code, we create information and research, we generate media, and we output full on products, right? Code and products is probably the most popular one for most engineers. Okay, so these things need to be super, super locked in. I probably should have explicitly added documentation, but it kind of fits under information as well. But you get the point, right? Like these are the first things to go after when you're trying to figure out what do I focus on? What do I automate? Right. And this is my plan for 2025 is It's to take all of my ingestion tasks and all of my synthesizing tasks and make sure that I can lean on generative AI tooling to help me accomplish that goal. So I have three big things queued up to share before the year ends that can accelerate your engineering. We're going to dive into meta-prompting concepts. We're going to start dipping our toes into what it looks like to get this 100x. Keep in mind that you don't jump between these productivity improvements. It takes a long time to transition and sometimes you're operating right out of chat gbt right getting the lower productivity gains and then other times you're going to use a specific tool or slew of agents i am going to be working really hard to get ada off the ground and make her as useful as possible for real software engineering because the gains here are just incredible. So we're going to be digging into meta prompting. I'll be releasing the AI coding course. I'm really, really excited about that. I've been working really, really hard for honestly over half a year now on this course. This is going to make you a master of AI coding tools, the tools of today and tomorrow. I want you to win not just today, but tomorrow next year, the year after. So I'm really excited to share that. That'll be closer to the end of the year, likely December. And then finally we'll be continuing to push on the capabilities of next generation AI tooling with a focus on of course shipping software from AI coding to crafting powerful prompts to deploying AI agents and building out our personal AI system all the way up to the fully agentic systems right this is our North Star that's where we're going on the channel. If that interests you, hit the like, hit the sub, join the journey. We are going to build a living software that works for us while we sleep. Stay focused and keep building.